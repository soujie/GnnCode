{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import torch.nn.init as init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency(edge_df, num_user, num_movie, symmetric_normalization):\n",
    "    user2movie_adjacencies = []\n",
    "    movie2user_adjacencies = []\n",
    "    train_edge_df = edge_df.loc[edge_df['usage'] == 'train']\n",
    "    for i in range(5):\n",
    "        edge_index = train_edge_df.loc[train_edge_df.ratings == i, [\n",
    "            'user_node_id', 'movie_node_id']].to_numpy()\n",
    "        support = sp.csr_matrix((np.ones(len(edge_index)), (edge_index[:, 0], edge_index[:, 1])),\n",
    "                                shape=(num_user, num_movie), dtype=np.float32)\n",
    "        user2movie_adjacencies.append(support)\n",
    "        movie2user_adjacencies.append(support.T)\n",
    "\n",
    "    user2movie_adjacencies = globally_normalize_bipartite_adjacency(user2movie_adjacencies,\n",
    "                                                                    symmetric=symmetric_normalization)\n",
    "    movie2user_adjacencies = globally_normalize_bipartite_adjacency(movie2user_adjacencies,\n",
    "                                                                    symmetric=symmetric_normalization)\n",
    "\n",
    "    return user2movie_adjacencies, movie2user_adjacencies\n",
    "\n",
    "#function\n",
    "\n",
    "def globally_normalize_bipartite_adjacency(adjacencies,symmetric=True):\n",
    "        '''\n",
    "        将2度图的adjacency matrics 进行全局标准化\n",
    "        ---------------\n",
    "        Args:\n",
    "                adjacencies  {list of sp.csr_matrix}   不同评分下的邻接矩阵\n",
    "        Return:\n",
    "                pass\n",
    "        '''\n",
    "        print('{} normalizing bipartite adj'.format(\n",
    "                ['Asymmetrically', 'Symmetrically'][symmetric]))\n",
    "\n",
    "        adj_tot=np.sum([adj for adj in adjacencies])\n",
    "        degree_u = np.asarray(adj_tot.sum(1)).flatten() #计算出度\n",
    "        degree_v = np.asarray(adj_tot.sum(0)).flatten()\n",
    "\n",
    "        degree_u[degree_u==0.]=np.inf  #将0重新赋值为inf ,避免除0\n",
    "        degree_v[degree_v==0.]=np.inf \n",
    "\n",
    "        degree_u_inv_sqrt=1./np.sqrt(degree_u)\n",
    "        degree_v_inv_sqrt=1./np.sqrt(degree_v)\n",
    "        degree_u_inv_sqrt_mat=sp.diags([degree_u_inv_sqrt],[0]) #转换为主对角线矩阵\n",
    "        degree_v_inv_sqrt_mat=sp.diags([degree_v_inv_sqrt],[0])\n",
    "\n",
    "        degree_u_inv = degree_u_inv_sqrt_mat.dot(degree_u_inv_sqrt_mat)\n",
    "\n",
    "        if symmetric:\n",
    "                adj_norm=[degree_u_inv_sqrt_mat.dot(adj).dot(degree_v_inv_sqrt_mat) for adj in adjacencies] #对邻接矩阵进行标注化, 实际上在构造随机游走矩阵?\n",
    "        else:\n",
    "                adj_norm=[degree_u_inv.dot(adj) for adj in adjacencies]\n",
    "                \n",
    "        return adj_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理用户侧、商品侧特征\n",
    "def get_user_side_feature(node_user:pd.DataFrame):\n",
    "    ''' 对用户节点属性特征进行处理, 包括年龄、性别、职业等'''\n",
    "    age=node_user['age'].to_numpy().astype('float32')\n",
    "    age/=age.max()\n",
    "    age=age.reshape((-1,1))\n",
    "    gender_arr,_=pd.factorize(node_user['gender']) #对类型变量进行离散化表示\n",
    "    gender_arr=np.reshape(gender_arr,(-1,1))\n",
    "    occupation_arr=pd.get_dummies(node_user['occupation']).to_numpy()\n",
    "\n",
    "    user_feature=np.concatenate([age,gender_arr,occupation_arr],axis=1)\n",
    "    return user_feature\n",
    "\n",
    "def get_movie_side_feature(node_movie:pd.DataFrame):\n",
    "    ''' 电影节点属性特征,主要是电影类型'''\n",
    "    movie_genre_cols = ['Action', 'Adventure', 'Animation',\n",
    "                        'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                        'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                        'Thriller', 'War', 'Western']\n",
    "    movie_genre_arr=node_movie.loc[:,movie_genre_cols].to_numpy().astype('float32')\n",
    "    return movie_genre_arr\n",
    "\n",
    "def normalize_feature(feature):\n",
    "    # return aij/sum_i(aij)\n",
    "    row_sum=feature.sum(1)\n",
    "    row_sum[row_sum==0]=np.inf \n",
    "    normalized_feat=feature/row_sum.reshape(-1,1)\n",
    "    return normalized_feat\n",
    "\n",
    "\n",
    "def convert_to_homogeneous(user_feature:pd.DataFrame,movie_feature:pd.DataFrame):\n",
    "    # 将用户侧和产品侧特征补零对齐\n",
    "    num_user,user_feature_dim=user_feature.shape\n",
    "    num_movie,movie_feature_dim=movie_feature.shape\n",
    "    user_feature=np.concatenate([user_feature,np.zeros((num_user,movie_feature_dim))],axis=1)\n",
    "    movie_feature=np.concatenate([np.zeros((num_movie,user_feature_dim)),movie_feature],axis=1)\n",
    "    return user_feature,movie_feature\n",
    "\n",
    "def get_node_identity_feature(num_user,num_movie):\n",
    "    'one hot encoding for all nodes (user node & product side)'\n",
    "    identity_feature=np.identity(num_user+num_movie,dtype=np.float32)\n",
    "    user_identity_feature,movie_identity_feature=identity_feature[:num_user],identity_feature[num_user:]\n",
    "    return user_identity_feature,movie_identity_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理数据\n",
    "class MovielensDataset():\n",
    "    url=\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    def __init__(self,data_root='data'):\n",
    "        self.data_root=data_root\n",
    "        self.maybe_download()\n",
    "        # self.url=\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    def maybe_download(self):\n",
    "        save_path=os.path.join(self.data_root)\n",
    "        if not os.path.exists(save_path): #若当前路径下无数据, 进行下载\n",
    "            self.download_data(self.url,save_path)\n",
    "        if not os.path.exists(os.path.join(self.data_root,\"ml-100k\")): #进行解压\n",
    "            zipfilename=os.path.join(self.data_root,'ml-100k.zip')\n",
    "            with ZipFile(zipfilename,'r') as zipobj:\n",
    "                zipobj.extractall(os.path.join(self.data_root))\n",
    "                print(\"Extracting data from {}\".format(zipfilename))\n",
    "    @staticmethod\n",
    "    def download_data(url: str , save_path :str ):\n",
    "        '下载数据'\n",
    "        print(\"Downloading data from {}\".format(url))     \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        request=urllib.request.urlopen(url)\n",
    "        filename=os.path.basename(url)\n",
    "        with open(os.path.join(save_path,filename),'wb') as f:\n",
    "            f.write(request.read())\n",
    "        return True\n",
    "    \n",
    "    def read_data(self):\n",
    "        '''\n",
    "        读取 产品侧特征,用户侧特征,边信息(已对训练集、测试集 进行划分)\n",
    "        '''\n",
    "        data_dir=os.path.join(self.data_root,'ml-100k')\n",
    "        \n",
    "        #edge data 只使用第一批数据进行处理\n",
    "        edge_train=pd.read_csv(os.path.join(data_dir,'u1.base'),sep='\\t',header=None,names=['user_node','movie_node','ratings','timestamp'])\n",
    "        edge_train.loc[:,'usage']='train'\n",
    "        edge_test=pd.read_csv(os.path.join(data_dir,'u1.test'),sep='\\t',header=None,names=['user_node','movie_node','ratings','timestamp'])\n",
    "        edge_test.loc[:,'usage']='test'\n",
    "        \n",
    "        edge_df=pd.concat((edge_train,edge_test),axis=0).drop(columns='timestamp')\n",
    "        edge_df.loc[:,'ratings']-=1\n",
    "        \n",
    "        #product sides features\n",
    "        sep=r'|'\n",
    "        movie_file=os.path.join(data_dir,'u.item')\n",
    "        movie_headers=['movie_node', 'movie_title', 'release_date', 'video_release_date',\n",
    "                         'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "                         'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                         'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                         'Thriller', 'War', 'Western']\n",
    "        movie_df=pd.read_csv(movie_file,sep=sep,header=None,names=movie_headers,encoding='latin1')\n",
    "        \n",
    "        #user side feature\n",
    "        users_file=os.path.join(data_dir,'u.user')\n",
    "        users_headers=['user_node','age','gender','occupation','zip_code']\n",
    "        users_df=pd.read_csv(users_file,sep=sep,header=None,names=users_headers,encoding='latin1')\n",
    "        \n",
    "        return edge_df,users_df,movie_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_graph(edge_df:pd.DataFrame,user_df:pd.DataFrame,movie_df:pd.DataFrame,symmetric_normalization=False):\n",
    "        '''\n",
    "        构建图\n",
    "        ---------------\n",
    "        Args:\n",
    "             edge_df  {pd.DataFrame}   边数据框\n",
    "             user_df  {pd.DataFrame}   用户侧特征\n",
    "             movie_df {pd.DataFrame}   产品侧特征\n",
    "             symmetric_normalization    {bool}  Laplace matrix 矩阵进行对称标准化处理\n",
    "        Return:\n",
    "            user2movie_adjacencies  [list of userXproduct adajacency matirx]  用户x产品的邻接矩阵list, 包含了不同的rating\n",
    "            movie2user_adjacencies  [list of productXuser adajacency matirx]  产品x用户的邻接矩阵list, 包含了不同的rating, 上者的转置\n",
    "            user_side_feature       [pd.DataFrame] 获得用户侧特征, 年龄啥的  \n",
    "            movie_side_feature      [pd.DataFrame] 获得产品侧特征\n",
    "            user_identity_feature   [np.array] 用户侧节点的one-hot 编码\n",
    "            movie_indentity_feature [np.array] 产品侧节点的one-hot 编码\n",
    "            user_indices            [np.array] 'user_node_id' 用户节点id\n",
    "            movie_indices           [np.array] 'movie_node_id' 产品节点id\n",
    "            labels                  [np.array] 'ratings' 边的标签\n",
    "            train_mask              [np.array bool] 训练集合mask\n",
    "        '''\n",
    "        # 获取用户侧和产品侧的 节点 \n",
    "        node_user=edge_df[['user_node']].drop_duplicates().sort_values('user_node')\n",
    "        node_movie=edge_df[['movie_node']].drop_duplicates().sort_values('movie_node')\n",
    "        node_user.loc[:,'user_node_id']=range(len(node_user))\n",
    "        node_movie.loc[:,'movie_node_id']=range(len(node_movie))\n",
    "        \n",
    "        #将edge_df 与用户侧节点idx和产品侧节点idx相结合\n",
    "        edge_df=edge_df.merge(node_user,on='user_node',how='left').merge(node_movie,on='movie_node',how='left')\n",
    "\n",
    "        #将节点idx 与 特征相结合\n",
    "        node_user=node_user.merge(user_df,on='user_node',how='left')\n",
    "        node_movie=node_movie.merge(movie_df, on='movie_node',how='left')\n",
    "        num_user=len(node_user)\n",
    "        num_movie=len(node_movie)\n",
    "        \n",
    "        #adjacenc\n",
    "        user2movie_adjacencies,movie2user_adjacencies=get_adjacency(edge_df,num_user,num_movie,symmetric_normalization)\n",
    "        \n",
    "        #node property feature \n",
    "        user_side_feature=get_user_side_feature(node_user)\n",
    "        movie_side_feature=get_movie_side_feature(node_movie)\n",
    "        user_side_feature=normalize_feature(user_side_feature)\n",
    "        movie_side_feature=normalize_feature(movie_side_feature)\n",
    "        user_side_feature,movie_side_feature=convert_to_homogeneous(user_side_feature,movie_side_feature)\n",
    "        \n",
    "        #one_hot encoding for nodes\n",
    "        user_identity_feature,movie_indentity_feature=get_node_identity_feature(num_user,num_movie)\n",
    "        \n",
    "        #user_indices,movie_indices,labels,train_mask\n",
    "        user_indices,movie_indices,labels=edge_df[['user_node_id', 'movie_node_id', 'ratings']].to_numpy().T \n",
    "        train_mask=(edge_df['usage']=='train').to_numpy()\n",
    "        \n",
    "        return user2movie_adjacencies, movie2user_adjacencies, \\\n",
    "            user_side_feature, movie_side_feature, \\\n",
    "            user_identity_feature, movie_indentity_feature, \\\n",
    "            user_indices, movie_indices, labels, train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义layer\n",
    "\n",
    "\n",
    "#定义\n",
    "class InputDropout(nn.Module):\n",
    "    def __init__(self, keep_prob):\n",
    "        super(InputDropout, self).__init__()\n",
    "        self.p = keep_prob\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.clone()\n",
    "        if self.training:\n",
    "            random_tensor = self.p + torch.rand(\n",
    "                (inputs.size(0), ))  #生成0-1 均匀分布\n",
    "            dropout_mask = torch.floor(random_tensor).bool()\n",
    "            x[~dropout_mask] = 0\n",
    "            return x / self.p\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class StackGCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_support,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False, activation=F.relu):\n",
    "        \"\"\"对得到的每类评分使用级联的方式进行聚合\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            num_support (int): 评分的类别数，比如1~5分，值为5\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "        \"\"\"\n",
    "        super(StackGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        assert output_dim % num_support == 0\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        \"\"\"StackGCNEncoder计算逻辑\n",
    "        \n",
    "        Args:\n",
    "            user_supports (list of torch.sparse.FloatTensor): \n",
    "                归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "            item_supports (list of torch.sparse.FloatTensor):\n",
    "                归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "            user_inputs (torch.Tensor): 用户特征的输入\n",
    "            item_inputs (torch.Tensor): 商品特征的输入\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 用户的隐层特征\n",
    "            [torch.Tensor]: 商品的隐层特征\n",
    "        \"\"\"\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weights = torch.split(self.weight, self.output_dim//self.num_support, dim=1)\n",
    "        for i in range(self.num_support):\n",
    "            tmp_u = torch.matmul(user_inputs, weights[i])\n",
    "            tmp_v = torch.matmul(item_inputs, weights[i])\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i], tmp_v)\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i], tmp_u)\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden = torch.cat(user_hidden, dim=1)\n",
    "        item_hidden = torch.cat(item_hidden, dim=1)\n",
    "\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_hidden)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class SumGCNEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int,\n",
    "                 num_support: int,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False,\n",
    "                 activation=F.relu):\n",
    "        '''\n",
    "        对得到的各类评分使用sum 的方式进行聚合\n",
    "        ---------------\n",
    "        Args:\n",
    "             input_dim  {int}   输入的特征维度\n",
    "             output_dim  {int }   输出的特征维度\n",
    "             num_support {int}  评分类型 例如1-5分\n",
    "             use_bias {bool} 是否使用截距项\n",
    "             activation {F.relu}   激活函数, 默认relu\n",
    "        Return:\n",
    "             pass\n",
    "        '''\n",
    "        super(SumGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.Tensor(input_dim, output_dim * num_support))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        '''\n",
    "        给予sum 的gcn encode\n",
    "        使用gcn 去拟合 mu & logvar\n",
    "        ---------------\n",
    "        Args:\n",
    "             user_supports  {list of torch.sparse.FloatTensor}   归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "             item_supports  {list of torch.sparse.FloatTensor}   归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "             user_inputs (torch.Tensor): 用户特征的输入\n",
    "             item_inputs (torch.Tensor): 商品特征的输入\n",
    "        Return:\n",
    "             [torch.Tensor] 用户的隐藏层特征\n",
    "             [torch.Tensor] 产品的隐藏层特征\n",
    "        '''\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weigths = torch.split(self.weight, self.output_dim, dim=1)  #按照列进行切分\n",
    "        for i in range(self.num_support):\n",
    "            w = sum(weights[:(i + 1)])  #前i层的权重相加\n",
    "            tmp_u = torch.matmul(user_inputs, w)\n",
    "            tmp_v = torch.matmul(item_inputs, w)\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i],\n",
    "                                              tmp_v)  # 用户侧邻接矩阵nxp, p为产品个数\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i],\n",
    "                                              tmp_u)  # 计算 AXW\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden, item_hidden = sum(user_hidden), sum(item_hidden)\n",
    "\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_outputs)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False,\n",
    "                 activation=F.relu,\n",
    "                 share_weights=False):\n",
    "        '''\n",
    "        非线形激活层\n",
    "        ---------------\n",
    "        Args:\n",
    "            input_dim  {int}   输入的特征维度\n",
    "            output_dim  {int}   输出的特征维度\n",
    "            dropout    {float}  dropout的比例\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "            share_weights (bool, optional): 用户和商品是否共享变换权值. Defaults to False.      \n",
    "        Return:\n",
    "             pass\n",
    "        '''\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.share_weights = share_weights\n",
    "        if not share_weights:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = self.weights_u\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if not self.share_weights:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            init.xavier_uniform_(self.weights_v)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "                init.normal_(self.item_bias, std=0.5)\n",
    "        else:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs):\n",
    "        '''\n",
    "        前向传播\n",
    "        ---------------\n",
    "        Args:\n",
    "            user_inputs  {torch.Tensor}   输出的用户特征\n",
    "            item_inputs  {torch.Tensor}   输出的用户特征\n",
    "        Return:\n",
    "            [torch.Tensor]: 输出的用户特征\n",
    "            [torch.Tensor]: 输出的商品特征\n",
    "        '''\n",
    "        x_u = self.dropout(user_inputs)\n",
    "        x_u = torch.matmul(x_u, self.weights_u)\n",
    "\n",
    "        x_v = self.dropout(item_inputs)\n",
    "        x_v = torch.matmul(x_v, self.weights_v)\n",
    "\n",
    "        u_outputs = self.activation(x_u)\n",
    "        v_outputs = self.activation(x_v)\n",
    "\n",
    "        if self.use_bias:\n",
    "            u_outputs += self.use_bias\n",
    "            v_outputs += self.item_bias\n",
    "        return u_outputs, v_outputs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 num_weights,\n",
    "                 num_classes,\n",
    "                 dropout=0.,\n",
    "                 activation=F.relu):\n",
    "        '''\n",
    "        解码器\n",
    "        ---------------\n",
    "        Args:\n",
    "            input_dim (int): 输入的特征维度\n",
    "            num_weights (int): basis weight number\n",
    "            num_classes (int): 总共的评分级别数，eg. 5\n",
    "        Return:\n",
    "             pass\n",
    "        '''\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_weights = num_weights\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "\n",
    "        self.weight = nn.ParameterList([\n",
    "            nn.Parameter(torch.Tensor(input_dim, input_dim))\n",
    "            for _ in range(num_weights)\n",
    "        ])\n",
    "        self.weight_classifier = nn.Parameter(\n",
    "            torch.Tensor(num_weights, num_classes))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            init.orthogonal_(self.weight[i], gain=1.1)\n",
    "        init.xavier_uniform_(self.weight_classifier)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs, user_indices, item_indices):\n",
    "        '''\n",
    "        计算非归一化的分类输出\n",
    "        ---------------\n",
    "        Args:\n",
    "            user_inputs (torch.Tensor): 用户的隐层特征\n",
    "            item_inputs (torch.Tensor): 商品的隐层特征\n",
    "            user_indices (torch.LongTensor): \n",
    "                所有交互行为中用户的id索引，与对应的item_indices构成一条边,shape=(num_edges, )\n",
    "            item_indices (torch.LongTensor): \n",
    "                所有交互行为中商品的id索引，与对应的user_indices构成一条边,shape=(num_edges, )\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 未归一化的分类输出，shape=(num_edges, num_classes)\n",
    "        '''\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "        user_inputs = user_inputs[user_indices]\n",
    "        item_inputs = item_inputs[item_indices]\n",
    "\n",
    "        basis_outputs = []\n",
    "        for i in range(self.num_weights):\n",
    "            tmp = torch.matmul(user_inputs, self.weigths[i])\n",
    "            out = torch.sum(tmp * item_inputs, dim=1, keepdim=True)\n",
    "            basis_outputs.append(out)\n",
    "\n",
    "        basis_outputs = torch.cat(basis_outputs, dim=1)\n",
    "\n",
    "        outputs = torch.matmul(basis_outputs, self, weight_classifier)\n",
    "        outputs = self.activation(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrixCompletion(nn.Module):\n",
    "    def __init__(self, input_dim, side_feat_dim,\n",
    "                 gcn_hidden_dim, side_hidden_dim,\n",
    "                 encode_hidden_dim,\n",
    "                 num_support=5, num_classes=5, num_basis=3):\n",
    "        super(GraphMatrixCompletion, self).__init__()\n",
    "        self.encoder = StackGCNEncoder(input_dim, gcn_hidden_dim, num_support, DROPOUT_RATIO)\n",
    "        self.dense1 = FullyConnected(side_feat_dim, side_hidden_dim, dropout=0.,\n",
    "                                     use_bias=True)\n",
    "        self.dense2 = FullyConnected(gcn_hidden_dim + side_hidden_dim, encode_hidden_dim,\n",
    "                                     dropout=DROPOUT_RATIO, activation=lambda x: x)\n",
    "        self.decoder = Decoder(encode_hidden_dim, num_basis, num_classes,\n",
    "                               dropout=DROPOUT_RATIO, activation=lambda x: x)\n",
    "\n",
    "    def forward(self, user_supports, item_supports,\n",
    "                user_inputs, item_inputs,\n",
    "                user_side_inputs, item_side_inputs,\n",
    "                user_edge_idx, item_edge_idx):\n",
    "        user_gcn, movie_gcn = self.encoder(user_supports, item_supports, user_inputs, item_inputs)\n",
    "        user_side_feat, movie_side_feat = self.dense1(user_side_inputs, item_side_inputs)\n",
    "\n",
    "        user_feat = torch.cat((user_gcn, user_side_feat), dim=1)\n",
    "        movie_feat = torch.cat((movie_gcn, movie_side_feat), dim=1)\n",
    "\n",
    "        user_embed, movie_embed = self.dense2(user_feat, movie_feat)\n",
    "\n",
    "        edge_logits = self.decoder(user_embed, movie_embed, user_edge_idx, item_edge_idx)\n",
    "\n",
    "        return edge_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch_sparse_tensor(x,device):\n",
    "    '将dataframe 转换为稀疏tensor'\n",
    "    if not sp.isspmatrix_coo(x):\n",
    "        x=sp.coo_matrix(x)\n",
    "    row,col=x.row,x.col \n",
    "    data=x.data \n",
    "    \n",
    "    indices=torch.from_numpy(np.asarray([row,col]).astype('int64')).long()\n",
    "    values=torch.from_numpy(x.data.astype(np.float32))\n",
    "    th_sparse_tensor=torch.sparse.FloatTensor(indices,values,x.shape).to(device)\n",
    "    \n",
    "def tensor_from_numpy(x,device):\n",
    "    return torch.from_numpy(x).to(device)\n",
    "\n",
    "def excepted_rmse(logits,label):\n",
    "    true_u=label+1\n",
    "    prob=F.softmax(logits,dim=1)\n",
    "    pred_y=torch.sum(prob*SCORES,dim=1)\n",
    "    diff=torch.pow(true_y-pred_y,2)\n",
    "    return torch.sqrt(diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数\n",
    "DEVICE=torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "LEARNING_RATE=0.015\n",
    "EPOCHS=1000\n",
    "NODE_INPUT_DIM=2625\n",
    "SIDE_FEATURE_DIM=41\n",
    "GCN_HIDDEN_DIM=500\n",
    "SIDE_HIDDEN_DIM=10\n",
    "ENCODE_HIDDEN_DIM=75\n",
    "NUM_BASIS=4\n",
    "DROPOUT_RATIO=0.7 \n",
    "WEIGHT_DACAY=0.\n",
    "\n",
    "\n",
    "SCORES=torch.tensor([[1,2,3,4,5]]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetrically normalizing bipartite adj\n",
      "Asymmetrically normalizing bipartite adj\n"
     ]
    }
   ],
   "source": [
    "data=MovielensDataset()\n",
    "user2movie_adjacencies, movie2user_adjacencies, user_side_feature, movie_side_feature, user_identity_feature, movie_identity_feature, user_indices, movie_indices, labels, train_mask = data.build_graph(*data.read_data())\n",
    "user2movie_adjacencies=[to_torch_sparse_tensor(adj,DEVICE) for adj in user2movie_adjacencies]\n",
    "movie2user_adjacencies=[to_torch_sparse_tensor(adj,DEVICE) for adj in movie2user_adjacencies]\n",
    "user_side_feature = tensor_from_numpy(user_side_feature,DEVICE).float()\n",
    "movie_side_feature=tensor_from_numpy(movie_side_feature,DEVICE).float()\n",
    "user_identity_feature=tensor_from_numpy(user_identity_feature,DEVICE).float()\n",
    "movie_identity_feature = tensor_from_numpy(movie_identity_feature, DEVICE).float()\n",
    "user_indices = tensor_from_numpy(user_indices, DEVICE).long()\n",
    "movie_indices = tensor_from_numpy(movie_indices, DEVICE).long()\n",
    "labels = tensor_from_numpy(labels, DEVICE)\n",
    "train_mask = tensor_from_numpy(train_mask, DEVICE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GraphMatrixCompletion(NODE_INPUT_DIM,SIDE_FEATURE_DIM,GCN_HIDDEN_DIM,SIDE_HIDDEN_DIM,ENCODE_HIDDEN_DIM,num_basis=NUM_BASIS).to(DEVICE)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE,weight_decay=WEIGHT_DACAY)\n",
    "model_inputs=(user2movie_adjacencies, movie2user_adjacencies,\n",
    "                user_identity_feature, movie_identity_feature,\n",
    "                user_side_feature, movie_side_feature, user_indices, movie_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    test_result=[]\n",
    "    model.train()\n",
    "    for e in range(EPOCHS):\n",
    "        logits=model(*model_inputs)\n",
    "        loss=criterion(logits[train_mask],labels[train_mask])\n",
    "        rmse=excepted_rmse(logits[train_mask],labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tr=test()\n",
    "        test_result.append(tr)\n",
    "        model.train()\n",
    "        print(f\"Epoch {e:04d}: TrainLoss: {loss.item():.4f}, TrainRMSE: {rmse.item():.4f}, \"\n",
    "              f\"TestRMSE: {tr[0]:.4f}, TestLoss: {tr[1]:.4f}\")\n",
    "        \n",
    "    test_result=np.asarray(test_result)\n",
    "    idx=test_result[:,0].argmin()\n",
    "    print(f'test min rmse {test_result[idx]} on epoch {idx}')\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(*model_inputs)\n",
    "    test_mask = ~train_mask\n",
    "    loss = criterion(logits[test_mask], labels[test_mask])\n",
    "    rmse = expected_rmse(logits[test_mask], labels[test_mask])\n",
    "    return rmse.item(), loss.item()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'is_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2r/2vpfv8ys6k53z86mjvfr46j40000gn/T/ipykernel_78028/3364925475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2r/2vpfv8ys6k53z86mjvfr46j40000gn/T/ipykernel_78028/1153552544.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcepted_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch1.9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2r/2vpfv8ys6k53z86mjvfr46j40000gn/T/ipykernel_78028/35985367.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_supports, item_supports, user_inputs, item_inputs, user_side_inputs, item_side_inputs, user_edge_idx, item_edge_idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0muser_side_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_side_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 user_edge_idx, item_edge_idx):\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0muser_gcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_gcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_supports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_supports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0muser_side_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_side_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_side_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_side_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch1.9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2r/2vpfv8ys6k53z86mjvfr46j40000gn/T/ipykernel_78028/3661781778.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_supports, item_supports, user_inputs, item_inputs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtmp_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtmp_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mtmp_user_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_supports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mtmp_item_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_supports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0muser_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_user_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch1.9/lib/python3.8/site-packages/torch/sparse/__init__.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(mat1, mat2)\u001b[0m\n\u001b[1;32m     87\u001b[0m                size=(2, 3), nnz=6, layout=torch.sparse_coo)\n\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmat2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_sparse_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_sparse'"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca001f4215888d8ea16b51ee26d57194a73bf1104676f49e8f5e52e35be82f9f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch1.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
