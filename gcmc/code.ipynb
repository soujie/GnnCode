{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图自编码应用 \n",
    "\n",
    "先用troch 版本进行测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import scipy.sparse as sp \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import torch.nn.init as init \n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "\n",
    "import random\n",
    "random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globally_normalize_bipartite_adjacencies(adjacencies,symmetric=True):\n",
    "    adj_tot = np.sum([adj for adj in adjacencies])\n",
    "    degree_u = np.asarray(adj_tot.sum(1)).flatten()\n",
    "    degree_v = np.asarray(adj_tot.sum(0)).flatten()\n",
    "\n",
    "    # set zeros to inf to avoid dividing by zero\n",
    "    degree_u[degree_u == 0.] = np.inf\n",
    "    degree_v[degree_v == 0.] = np.inf\n",
    "\n",
    "    degree_u_inv_sqrt = 1. / np.sqrt(degree_u)\n",
    "    degree_v_inv_sqrt = 1. / np.sqrt(degree_v)\n",
    "    degree_u_inv_sqrt_mat = sp.diags([degree_u_inv_sqrt], [0])\n",
    "    degree_v_inv_sqrt_mat = sp.diags([degree_v_inv_sqrt], [0])\n",
    "\n",
    "    degree_u_inv = degree_u_inv_sqrt_mat.dot(degree_u_inv_sqrt_mat)\n",
    "\n",
    "    if symmetric:\n",
    "        adj_norm = [degree_u_inv_sqrt_mat.dot(adj).dot(\n",
    "            degree_v_inv_sqrt_mat) for adj in adjacencies]\n",
    "\n",
    "    else:\n",
    "        adj_norm = [degree_u_inv.dot(adj) for adj in adjacencies]\n",
    "\n",
    "    return adj_norm\n",
    "\n",
    "def get_adjacency(edge_df,num_user,num_movie,sysmetric_normalization):\n",
    "     user2item_adj=[]\n",
    "     item2user_adj=[]\n",
    "     train_edge_df=edge_df.loc[edge_df['usage']==1]\n",
    "     edge_index=train_edge_df.loc[:,['userId', 'movieId']].to_numpy()\n",
    "     support = sp.csr_matrix((np.ones(len(edge_index)), (edge_index[:, 0], edge_index[:, 1])),\n",
    "                                shape=(num_user, num_movie), dtype=np.float32)\n",
    "     user2item_adj.append(support)\n",
    "     item2user_adj.append(support.T)\n",
    "     \n",
    "     user2item_adj=globally_normalize_bipartite_adjacencies(user2item_adj,symmetric=sysmetric_normalization)\n",
    "     item2user_adj=globally_normalize_bipartite_adjacencies(item2user_adj,symmetric=sysmetric_normalization)\n",
    "     \n",
    "     return user2item_adj,item2user_adj\n",
    "\n",
    "def get_node_identity_feature(nums_user,nums_item):\n",
    "     identity_feature=np.identity(nums_user+nums_item,dtype=np.float32)\n",
    "     user_identity_feature,item_identity_feature=identity_feature[:nums_user],identity_feature[nums_user:]\n",
    "     return user_identity_feature,item_identity_feature\n",
    "\n",
    "def checkId(traindf:pd.DataFrame,testdf:pd.DataFrame):\n",
    "     ''' 保证testdf 中的userId 和itemId 在traindf中出现过'''\n",
    "     totalTrainUserId=traindf['userId'].drop_duplicates()\n",
    "     testdf=testdf.loc[testdf['userId'].apply(lambda x: x  in totalTrainUserId),:]\n",
    "     totalTrainItemId=traindf['movieId'].drop_duplicates()\n",
    "     testdf=testdf.loc[testdf['movieId'].apply(lambda x: x in totalTrainItemId),:]\n",
    "     return testdf\n",
    " \n",
    "               \n",
    "          \n",
    "     \n",
    "\n",
    "def load_data(ratings:pd.DataFrame):\n",
    "     '''\n",
    "    处理数据, 输出邻接矩阵和特征矩阵(目前将rating 处理为0,1 情况, 只考虑其是否acting)\n",
    "    ---------------\n",
    "     Args:\n",
    "          ratings  {pd.DataFrame} \n",
    "     Return:\n",
    "          num_users  : int \n",
    "          Number of users and items\n",
    "          num_items  : int\n",
    "          \n",
    "          user_indices   : np.int32 arrays\n",
    "          User indices\n",
    "          item_indices   : np.int32 arrays\n",
    "          Item indices\n",
    "          \n",
    "          user2item_adjs,item2user_adjs:  np.float32 arrays\n",
    "          不同rating 下的User/Item 邻接矩阵\n",
    "          \n",
    "          train_mask     :np.bool arrays\n",
    "          \n",
    "     '''\n",
    "     movieids=ratings.movieId.drop_duplicates()\n",
    "     movieDicts={u:v for u,v in zip(movieids,range(len(movieids)))}\n",
    "     ratings['userId']=ratings['userId']-1\n",
    "     ratings['movieId']=ratings.movieId.map(movieDicts)\n",
    "     ratings['usage']=np.random.binomial(1,0.8,ratings.shape[0])\n",
    "     X_train,X_val=train_test_split(ratings.loc[ratings['usage']==1,:],test_size=0.25)\n",
    "     X_val=checkId(X_train,X_val)\n",
    "     X_train['usage']=1\n",
    "     X_val['usage']=0\n",
    "     X=pd.concat([X_train,X_val],axis=0)\n",
    "     X['label']=1\n",
    "     X_test=ratings.loc[ratings['usage']==0,:] #NOTE testset 需要重新写!!!!!\n",
    "     X_test=checkId(X,X_test)\n",
    "     X_test['label']=1\n",
    "     \n",
    "     \n",
    "     num_users=X.userId.max()+1\n",
    "     num_items=X.movieId.max()+1\n",
    "\n",
    "     user2item_adjs,item2user_adjs=get_adjacency(X,num_users,num_items,sysmetric_normalization=True)\n",
    "     \n",
    "     #one-hot encoding for nodes\n",
    "     user_indentity_feature, item_indentity_feature = get_node_identity_feature(num_users,num_items)\n",
    "     \n",
    "     train_mask=(X['usage']==1).to_numpy()\n",
    "     user_indices,item_indices=X[['userId','movieId']].to_numpy().T\n",
    "     user_indices_test,item_indices_test=X_test[['userId','movieId']].to_numpy().T\n",
    "\n",
    "     train_labels=X['label'].to_numpy()\n",
    "     test_labels=X_test['label'].to_numpy()\n",
    "\n",
    "     return user2item_adjs,item2user_adjs,\\\n",
    "          user_indentity_feature,item_indentity_feature,\\\n",
    "          user_indices,item_indices,user_indices_test,item_indices_test,\\\n",
    "          train_labels,test_labels,train_mask,num_users,num_items\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=pd.read_csv('data/ratings.csv')\n",
    "\n",
    "\n",
    "user2item_adjs,item2user_adjs,user_indentity_feature,item_indentity_feature,\\\n",
    "    user_indices,item_indices,user_indices_test,item_indices_test,\\\n",
    "        train_labels,test_labels,train_mask,num_users,num_items=load_data(ratings) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294.6162"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2item_adjs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InputDropout(nn.Module):\n",
    "    def __init__(self, keep_prob):\n",
    "        super(InputDropout, self).__init__()\n",
    "        self.p = keep_prob\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.clone()\n",
    "        if self.training:\n",
    "            random_tensor = self.p + torch.rand((inputs.size(0),))\n",
    "            dropout_mask = torch.floor(random_tensor).bool()\n",
    "            x[~dropout_mask] = 0.\n",
    "            return x / self.p\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class StackGCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_support,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False, activation=F.relu):\n",
    "        \"\"\"对得到的每类评分使用级联的方式进行聚合\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 总节点个数\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            num_support (int): 评分的类别数，比如1~5分，值为5\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "        \"\"\"\n",
    "        super(StackGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        assert output_dim % num_support == 0\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        \"\"\"StackGCNEncoder计算逻辑\n",
    "        \n",
    "        Args:\n",
    "            user_supports (list of torch.sparse.FloatTensor): \n",
    "                归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "            item_supports (list of torch.sparse.FloatTensor):\n",
    "                归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "            user_inputs (torch.Tensor): 用户特征的输入\n",
    "            item_inputs (torch.Tensor): 商品特征的输入\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 用户的隐层特征\n",
    "            [torch.Tensor]: 商品的隐层特征\n",
    "        \"\"\"\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weights = torch.split(self.weight, self.output_dim//self.num_support, dim=1)\n",
    "        for i in range(self.num_support):\n",
    "            tmp_u = torch.matmul(user_inputs, weights[i]) #Nu x D\n",
    "            tmp_v = torch.matmul(item_inputs, weights[i]) #Ni x D\n",
    "            assert user_supports[i].shape[1]==tmp_v.shape[0],'user_adj shape:{},tmp_v shape:{}'.format(user2item_adjs[0].shape,tmp_v.shape)\n",
    "            assert item_supports[i].shape[1]==tmp_u.shape[0],'user_adj shape:{},tmp_v shape:{}'.format(user2item_adjs[0].shape,tmp_v.shape)\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i], tmp_v)\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i], tmp_u)\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden = torch.cat(user_hidden, dim=1)\n",
    "        item_hidden = torch.cat(item_hidden, dim=1)\n",
    "\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_hidden)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class SumGCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_support,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False, activation=F.relu):\n",
    "        \"\"\"对得到的每类评分使用求和的方式进行聚合\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            num_support (int): 评分的类别数，比如1~5分，值为5\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "        \"\"\"\n",
    "        super(SumGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.weight = nn.Parameter(torch.Tensor(\n",
    "            input_dim, output_dim * num_support))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        \"\"\"SumGCNEncoder计算逻辑\n",
    "        \n",
    "        Args:\n",
    "            user_supports (list of torch.sparse.FloatTensor): \n",
    "                归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "            item_supports (list of torch.sparse.FloatTensor):\n",
    "                归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "            user_inputs (torch.Tensor): 用户特征的输入\n",
    "            item_inputs (torch.Tensor): 商品特征的输入\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 用户的隐层特征\n",
    "            [torch.Tensor]: 商品的隐层特征\n",
    "        \"\"\"\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "\n",
    "\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weights = torch.split(self.weight, self.output_dim, dim=1)\n",
    "        for i in range(self.num_support):\n",
    "            w = sum(weights[:(i + 1)])\n",
    "            tmp_u = torch.matmul(user_inputs, w)\n",
    "            tmp_v = torch.matmul(item_inputs, w)\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i], tmp_v)\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i], tmp_u)\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden, item_hidden = sum(user_hidden), sum(item_hidden)\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_hidden)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.,\n",
    "                 use_bias=False, activation=F.relu,\n",
    "                 share_weights=False):\n",
    "        \"\"\"非线性变换层\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "            share_weights (bool, optional): 用户和商品是否共享变换权值. Defaults to False.\n",
    "        \n",
    "        \"\"\"\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.share_weights = share_weights\n",
    "        if not share_weights:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = self.weights_u\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = self.user_bias\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if not self.share_weights:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            init.xavier_uniform_(self.weights_v)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "                init.normal_(self.item_bias, std=0.5)\n",
    "        else:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs):\n",
    "        \"\"\"前向传播\n",
    "        \n",
    "        Args:\n",
    "            user_inputs (torch.Tensor): 输入的用户特征\n",
    "            item_inputs (torch.Tensor): 输入的商品特征\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 输出的用户特征\n",
    "            [torch.Tensor]: 输出的商品特征\n",
    "        \"\"\"\n",
    "        x_u = self.dropout(user_inputs)\n",
    "        x_u = torch.matmul(x_u, self.weights_u)\n",
    "\n",
    "        x_v = self.dropout(item_inputs)\n",
    "        x_v = torch.matmul(x_v, self.weights_v)\n",
    "\n",
    "        u_outputs = self.activation(x_u)\n",
    "        v_outputs = self.activation(x_v)\n",
    "\n",
    "        if self.use_bias:\n",
    "            u_outputs += self.user_bias\n",
    "            v_outputs += self.item_bias\n",
    "\n",
    "        return u_outputs, v_outputs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_weights, num_classes, dropout=0., activation=F.relu):\n",
    "        \"\"\"解码器\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            num_weights (int): basis weight number\n",
    "            num_classes (int): 总共的评分级别数，eg. 5\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_weights = num_weights\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.weight = nn.ParameterList([nn.Parameter(torch.Tensor(input_dim, input_dim))\n",
    "                                        for _ in range(num_weights)])\n",
    "        self.weight_classifier = nn.Parameter(torch.Tensor(num_weights, num_classes))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            init.orthogonal_(self.weight[i], gain=1.1)\n",
    "        init.xavier_uniform_(self.weight_classifier)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs, user_indices, item_indices,predicted=False):\n",
    "        \"\"\"计算非归一化的分类输出\n",
    "        \n",
    "        Args:\n",
    "            user_inputs (torch.Tensor): 用户的隐层特征\n",
    "            item_inputs (torch.Tensor): 商品的隐层特征\n",
    "            user_indices (torch.LongTensor): \n",
    "                所有交互行为中用户的id索引，与对应的item_indices构成一条边,shape=(num_edges, )\n",
    "            item_indices (torch.LongTensor): \n",
    "                所有交互行为中商品的id索引，与对应的user_indices构成一条边,shape=(num_edges, )\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 未归一化的分类输出，shape=(num_edges, num_classes)\n",
    "        \"\"\"\n",
    "        if not predicted:\n",
    "            user_inputs = self.dropout(user_inputs)\n",
    "            item_inputs = self.dropout(item_inputs)\n",
    "        user_inputs = user_inputs[user_indices]\n",
    "        item_inputs = item_inputs[item_indices]\n",
    "        \n",
    "        basis_outputs = []\n",
    "        for i in range(self.num_weights):\n",
    "            tmp = torch.matmul(user_inputs, self.weight[i])\n",
    "            out = torch.sum(tmp * item_inputs, dim=1, keepdim=True)\n",
    "            basis_outputs.append(out)\n",
    "\n",
    "        basis_outputs = torch.cat(basis_outputs, dim=1)\n",
    "        \n",
    "        outputs = torch.matmul(basis_outputs, self.weight_classifier)\n",
    "        outputs = self.activation(outputs)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch_sparse_tensor(x, device):\n",
    "    if not sp.isspmatrix_coo(x):\n",
    "        x = sp.coo_matrix(x)\n",
    "    row, col = x.row, x.col\n",
    "    data = x.data\n",
    "\n",
    "    indices = torch.from_numpy(np.asarray([row, col]).astype('int64')).long()\n",
    "    values = torch.from_numpy(x.data.astype(np.float32))\n",
    "    th_sparse_tensor = torch.sparse.FloatTensor(indices, values,\n",
    "                                                x.shape).to(device)\n",
    "\n",
    "    return th_sparse_tensor\n",
    "\n",
    "\n",
    "def tensor_from_numpy(x, device):\n",
    "\n",
    "    return torch.from_numpy(x).to(device)\n",
    "\n",
    "def returnx(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class GraphMatrixCompletion(nn.Module):\n",
    "    def __init__(self, input_dim, gcn_hidden_dim,\n",
    "                 encode_hidden_dim,\n",
    "                 num_support=1, num_classes=2, num_basis=4):\n",
    "        super(GraphMatrixCompletion, self).__init__()\n",
    "        self.u_embed=None\n",
    "        self.i_embed=None\n",
    "        self.encoder = StackGCNEncoder(input_dim, gcn_hidden_dim, num_support, dropout=DROPOUT_RATIO)\n",
    "        # self.dense1 = FullyConnected(side_feat_dim, side_hidden_dim, dropout=0.,use_bias=True)\n",
    "        self.dense2 = FullyConnected(gcn_hidden_dim, encode_hidden_dim,\n",
    "                                     dropout=DROPOUT_RATIO, activation=returnx)\n",
    "        self.decoder = Decoder(encode_hidden_dim, num_basis, num_classes,\n",
    "                               dropout=DROPOUT_RATIO, activation=returnx)\n",
    "\n",
    "    def forward(self, user_supports, item_supports,\n",
    "                user_inputs, item_inputs,\n",
    "                user_edge_idx, item_edge_idx):    #不使用feature\n",
    "    # def forward(self, user_supports, item_supports,\n",
    "    #             user_inputs, item_inputs,\n",
    "    #             user_side_inputs, item_side_inputs,\n",
    "    #             user_edge_idx, item_edge_idx):\n",
    "        user_gcn, movie_gcn = self.encoder(user_supports, item_supports, user_inputs, item_inputs)\n",
    "        # user_side_feat, movie_side_feat = self.dense1(user_side_inputs, item_side_inputs)\n",
    "\n",
    "        # user_feat = torch.cat((user_gcn, user_side_feat), dim=1)\n",
    "        # movie_feat = torch.cat((movie_gcn, movie_side_feat), dim=1)\n",
    "        user_feat,movie_feat=user_gcn,movie_gcn\n",
    "        user_embed, movie_embed = self.dense2(user_feat, movie_feat)\n",
    "        \n",
    "        # global u_embed\n",
    "        # global i_embed\n",
    "        self.u_embed=user_embed\n",
    "        self.i_embed=movie_embed\n",
    "        edge_logits = self.decoder(user_embed, movie_embed, user_edge_idx, item_edge_idx)\n",
    "\n",
    "        return edge_logits\n",
    "\n",
    "    def predict(self, user_edge_idx, item_edge_idx):\n",
    "\n",
    "        return self.decoder(self.u_embed,self.i_embed,user_edge_idx,item_edge_idx,predicted=True).argmax(dim=1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "LEARNING_RATE = 0.015\n",
    "EPOCHS = 20\n",
    "NODE_INPUT_DIM = num_items+num_users\n",
    "# SIDE_FEATURE_DIM = 41\n",
    "GCN_HIDDEN_DIM = 100\n",
    "# SIDE_HIDDEN_DIM = 10\n",
    "ENCODE_HIDDEN_DIM = 75\n",
    "NUM_BASIS = 4\n",
    "DROPOUT_RATIO = 0.8\n",
    "WEIGHT_DACAY = 0.\n",
    "SCORES = torch.tensor([[0,1]]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2movie_adjacencies = [to_torch_sparse_tensor(adj, DEVICE) for adj in user2item_adjs]\n",
    "movie2user_adjacencies = [to_torch_sparse_tensor(adj, DEVICE) for adj in item2user_adjs]\n",
    "user_identity_feature = tensor_from_numpy(user_indentity_feature, DEVICE).float()\n",
    "movie_identity_feature = tensor_from_numpy(item_indentity_feature, DEVICE).float()\n",
    "user_indices = tensor_from_numpy(user_indices, DEVICE).long()\n",
    "movie_indices = tensor_from_numpy(item_indices, DEVICE).long()\n",
    "labels = tensor_from_numpy(train_labels, DEVICE)\n",
    "train_mask = tensor_from_numpy(train_mask, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphMatrixCompletion(NODE_INPUT_DIM, GCN_HIDDEN_DIM,\n",
    "                             ENCODE_HIDDEN_DIM, num_basis=NUM_BASIS).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DACAY)\n",
    "model_inputs = (user2movie_adjacencies, movie2user_adjacencies,\n",
    "                user_identity_feature, movie_identity_feature, user_indices, movie_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "# criterion = nn.BCELoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DACAY)\n",
    "\n",
    "def train():\n",
    "    val_result = []\n",
    "    model.train()\n",
    "    for e in range(EPOCHS):\n",
    "        t=time.time()\n",
    "        logits = model(*model_inputs)\n",
    "        logit=logits[train_mask]\n",
    "        label= labels[train_mask]\n",
    "        loss = criterion(logit,label)\n",
    "        rmse = expected_rmse(logit,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        tr = test()\n",
    "        val_result.append(tr)\n",
    "        model.train()\n",
    "        print(f\"Epoch {e:04d}: TrainLoss: {loss.item():.4f}, TrainRMSE: {rmse.item():.4f}, \"\n",
    "              f\"ValRMSE: {tr[0]:.4f}, ValLoss: {tr[1]:.4f},Times :{time.time()-t}\")\n",
    "\n",
    "    val_result = np.asarray(val_result)\n",
    "    idx = val_result[:, 0].argmin()\n",
    "    print(f'test min rmse {val_result[idx]} on epoch {idx}')\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(*model_inputs)\n",
    "    val_mask = ~train_mask\n",
    "    logit= logits[val_mask]\n",
    "    label= labels[val_mask]\n",
    "    loss = criterion(logit, label)\n",
    "    rmse = expected_rmse(logit, label)\n",
    "    return rmse.item(), loss.item()\n",
    "\n",
    "\n",
    "def expected_rmse(logits, label):\n",
    "    true_y = label \n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    pred_y = torch.sum(prob * SCORES, dim=1)\n",
    "    \n",
    "    diff = torch.pow(true_y - pred_y, 2)\n",
    "    \n",
    "    return torch.sqrt(diff.mean())\n",
    "\n",
    "def predictTestSet(user_indices_test,item_indices_test):\n",
    "    pred=model.predict(user_indices_test,item_indices_test)\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: TrainLoss: 0.6932, TrainRMSE: 0.5000, ValRMSE: 0.4998, ValLoss: 0.6927\n",
      "Epoch 0001: TrainLoss: 0.6915, TrainRMSE: 0.4992, ValRMSE: 0.4957, ValLoss: 0.6845\n",
      "Epoch 0002: TrainLoss: 0.6788, TrainRMSE: 0.4928, ValRMSE: 0.4680, ValLoss: 0.6311\n",
      "Epoch 0003: TrainLoss: 0.5742, TrainRMSE: 0.4393, ValRMSE: 0.3471, ValLoss: 0.4226\n",
      "Epoch 0004: TrainLoss: 0.4191, TrainRMSE: 0.3603, ValRMSE: 0.1171, ValLoss: 0.0991\n",
      "Epoch 0005: TrainLoss: 0.2018, TrainRMSE: 0.2387, ValRMSE: 0.0045, ValLoss: 0.0026\n",
      "Epoch 0006: TrainLoss: 0.1303, TrainRMSE: 0.2018, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0007: TrainLoss: 0.0772, TrainRMSE: 0.1623, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0008: TrainLoss: 0.0851, TrainRMSE: 0.1746, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0009: TrainLoss: 0.1208, TrainRMSE: 0.2082, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0010: TrainLoss: 0.0728, TrainRMSE: 0.1619, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0011: TrainLoss: 0.1001, TrainRMSE: 0.1899, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0012: TrainLoss: 0.0745, TrainRMSE: 0.1639, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0013: TrainLoss: 0.0914, TrainRMSE: 0.1816, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0014: TrainLoss: 0.0794, TrainRMSE: 0.1692, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0015: TrainLoss: 0.1033, TrainRMSE: 0.1930, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0016: TrainLoss: 0.1105, TrainRMSE: 0.1997, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0017: TrainLoss: 0.1139, TrainRMSE: 0.2027, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0018: TrainLoss: 0.0746, TrainRMSE: 0.1640, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "Epoch 0019: TrainLoss: 0.1097, TrainRMSE: 0.1989, ValRMSE: 0.0000, ValLoss: 0.0000\n",
      "test min rmse [0. 0.] on epoch 7\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DataSet \n",
      " f1 score:0.9105164724500072 , recall score: 0.8357322065231745,acc score:0.8357322065231745\n",
      "Train DataSet \n",
      " f1 score:0.9105347410831519 , recall score: 0.8357629888890723,acc score:0.8357629888890723\n",
      "Val DataSet \n",
      " f1 score:0.8181818181818181 , recall score: 0.6923076923076923,acc score:0.6923076923076923\n",
      "Test DataSet \n",
      " f1 score:0.6538461538461539 , recall score: 0.6538461538461539,acc score:0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,roc_auc_score\n",
    "val_mask = ~train_mask\n",
    "preds=model(*model_inputs).argmax(dim=1)\n",
    "test_pred=predictTestSet(user_indices_test,item_indices_test)\n",
    "\n",
    "print('Total DataSet \\n f1 score:{} , recall score: {},acc score:{}'.format(f1_score(labels,preds),recall_score(labels,preds),accuracy_score(labels,preds)))\n",
    "print('Train DataSet \\n f1 score:{} , recall score: {},acc score:{}'.format(f1_score(labels[train_mask],preds[train_mask]),recall_score(labels[train_mask],preds[train_mask]),accuracy_score(labels[train_mask],preds[train_mask])))\n",
    "print('Val DataSet \\n f1 score:{} , recall score: {},acc score:{}'.format(f1_score(labels[val_mask],preds[val_mask]),recall_score(labels[val_mask],preds[val_mask]),accuracy_score(labels[val_mask],preds[val_mask])))\n",
    "# print('Test DataSet \\n f1 score:{} , recall score: {},acc score:{}, auc score:{}'.format(f1_score(test_labels,test_pred),recall_score(test_labels,test_pred),accuracy_score(test_labels,test_pred),roc_auc_score(test_labels,test_pred)))\n",
    "print('Test DataSet \\n f1 score:{} , recall score: {},acc score:{}'.format(f1_score(test_labels,test_pred),recall_score(test_labels,test_pred),accuracy_score(test_labels,test_pred)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "11  6111\n",
       "15  3114\n",
       "25  8744"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=pd.DataFrame({'name':item_indices_test})\n",
    "b.loc[b['name'].apply(lambda x : x not in item_indices),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency1(edge_df,num_user,num_movie,sysmetric_normalization):\n",
    "     ratings['usage']='train'\n",
    "     user2item_adj=[]\n",
    "     item2user_adj=[]\n",
    "     train_edge_df=edge_df.loc[edge_df['usage']=='train']\n",
    "     edge_index=train_edge_df.loc[:,['userId', 'movieId']].to_numpy()\n",
    "     support = sp.csr_matrix((np.ones(len(edge_index)), (edge_index[:, 0], edge_index[:, 1])),\n",
    "                                shape=(num_user, num_movie), dtype=np.float32)\n",
    "     user2item_adj.append(support)\n",
    "     item2user_adj.append(support.T)\n",
    "     \n",
    "    #  user2item_adj=globally_normalize_bipartite_adjacencies(user2item_adj,symmetric=sysmetric_normalization)\n",
    "    #  item2user_adj=globally_normalize_bipartite_adjacencies(item2user_adj,symmetric=sysmetric_normalization)\n",
    "     \n",
    "     return user2item_adj,item2user_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     num_users=ratings.userId.max()+1\n",
    "     num_items=ratings.movieId.max()+1\n",
    "\n",
    "     user2item_adjs,item2user_adjs=get_adjacency1(ratings,num_users,num_items,sysmetric_normalization=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<610x9724 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2item_adjs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca001f4215888d8ea16b51ee26d57194a73bf1104676f49e8f5e52e35be82f9f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch1.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
