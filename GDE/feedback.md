# Model Feedback

# Q:
1. 目前实现的效果距离论文标注的还是有一部分差距
   1. Pinterest & MovieLens 100k 实现的效果和所述的GDE-d 差不多
   2. 可能是参数调节的问题?
2. 实现细节上与论文所述不一致
   1. Item 度矩阵, 原始code 中未求sqrt
   2. 优化器用的是adamw , 原始用的是sgd
      1. 非sgd 情况下, 容易梯度爆炸
         1. 采用较低的学习率(1e-3,1e-4)
         2. 采用norm 梯度裁剪
      2. sgd 收敛过慢
      3. 优化器还是应该选择AdamW , 缺失收敛的快
   3. 原始代码中BPR loss 不对
   4. L2 惩罚部分不同
   5. MovieLens_100k 数据集下, bpr loss 比adaptive loss 要好点
   
3. 可优化点:
   1. static 滤波器中可加入度信息(虽然感觉可能没啥用)
   2. 预处理阶段中, 谱分解迭代次数定为5 , 后面可以试试调大了看看(可能会对模型性能有微量的提升)
   3. ~~预处理阶段直接用torch.sparse_coo_tensor 会好点?~~ 
      1. ~~稀疏矩阵乘法会不会快点?~~
      1. 预处理阶段采用scipy.sparse.csr_matric 加速矩阵乘法, torch 进行谱分解的步骤的也输入coo_sparse_tensor 格式, 速度加快了很多, 但目前不足的是 Pinterest 数据集这样节点数相对较大的情况下, 预处理过程还是很慢(both 情况下, smooth 采样10% , rough 采样0.2% 差不多用了1h).
   4. 正负采样部分可改进下思路:
      1. 现在的正负采样都是基于购买行为设定权重, 并且每次每个user 只采样一个item
      2. 如果在不大幅度改进模型的基础上, 可以正样本一次性采样K *n 个, 负样本只采样n 个, 将正样本分成K 份, 和一致的负样本构成K 份训练数据 feedback 给模型, 应该能加快模型收敛
   5. 还是得找找方法解决下数据预处理过程的耗时问题
