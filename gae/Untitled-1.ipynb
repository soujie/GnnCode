{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import torch.nn.init as init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globally_normalize_bipartite_adjacency(adjacencies, symmetric=True):\n",
    "    \"\"\" Globally Normalizes set of bipartite adjacency matrices \"\"\"\n",
    "\n",
    "    print('{} normalizing bipartite adj'.format(\n",
    "        ['Asymmetrically', 'Symmetrically'][symmetric]))\n",
    "\n",
    "    adj_tot = np.sum([adj for adj in adjacencies])\n",
    "    degree_u = np.asarray(adj_tot.sum(1)).flatten()\n",
    "    degree_v = np.asarray(adj_tot.sum(0)).flatten()\n",
    "\n",
    "    # set zeros to inf to avoid dividing by zero\n",
    "    degree_u[degree_u == 0.] = np.inf\n",
    "    degree_v[degree_v == 0.] = np.inf\n",
    "\n",
    "    degree_u_inv_sqrt = 1. / np.sqrt(degree_u)\n",
    "    degree_v_inv_sqrt = 1. / np.sqrt(degree_v)\n",
    "    degree_u_inv_sqrt_mat = sp.diags([degree_u_inv_sqrt], [0])\n",
    "    degree_v_inv_sqrt_mat = sp.diags([degree_v_inv_sqrt], [0])\n",
    "\n",
    "    degree_u_inv = degree_u_inv_sqrt_mat.dot(degree_u_inv_sqrt_mat)\n",
    "\n",
    "    if symmetric:\n",
    "        adj_norm = [degree_u_inv_sqrt_mat.dot(adj).dot(\n",
    "            degree_v_inv_sqrt_mat) for adj in adjacencies]\n",
    "\n",
    "    else:\n",
    "        adj_norm = [degree_u_inv.dot(adj) for adj in adjacencies]\n",
    "\n",
    "    return adj_norm\n",
    "\n",
    "\n",
    "def get_adjacency(edge_df, num_user, num_movie, symmetric_normalization):\n",
    "    user2movie_adjacencies = []\n",
    "    movie2user_adjacencies = []\n",
    "    train_edge_df = edge_df.loc[edge_df['usage'] == 'train']\n",
    "    for i in range(5):\n",
    "        edge_index = train_edge_df.loc[train_edge_df.ratings == i, [\n",
    "            'user_node_id', 'movie_node_id']].to_numpy()\n",
    "        support = sp.csr_matrix((np.ones(len(edge_index)), (edge_index[:, 0], edge_index[:, 1])),\n",
    "                                shape=(num_user, num_movie), dtype=np.float32)\n",
    "        user2movie_adjacencies.append(support)\n",
    "        movie2user_adjacencies.append(support.T)\n",
    "\n",
    "    user2movie_adjacencies = globally_normalize_bipartite_adjacency(user2movie_adjacencies,\n",
    "                                                                    symmetric=symmetric_normalization)\n",
    "    movie2user_adjacencies = globally_normalize_bipartite_adjacency(movie2user_adjacencies,\n",
    "                                                                    symmetric=symmetric_normalization)\n",
    "\n",
    "    return user2movie_adjacencies, movie2user_adjacencies\n",
    "\n",
    "\n",
    "def get_node_identity_feature(num_user, num_movie):\n",
    "    \"\"\"one-hot encoding for nodes\"\"\"\n",
    "    identity_feature = np.identity(num_user + num_movie, dtype=np.float32)\n",
    "    user_identity_feature, movie_indentity_feature = identity_feature[\n",
    "        :num_user], identity_feature[num_user:]\n",
    "\n",
    "    return user_identity_feature, movie_indentity_feature\n",
    "\n",
    "\n",
    "def get_user_side_feature(node_user: pd.DataFrame):\n",
    "    \"\"\"用户节点属性特征，包括年龄，性别，职业\"\"\"\n",
    "    age = node_user['age'].to_numpy().astype('float32')\n",
    "    age /= age.max()\n",
    "    age = age.reshape((-1, 1))\n",
    "    gender_arr, gender_index = pd.factorize(node_user['gender'])\n",
    "    gender_arr = np.reshape(gender_arr, (-1, 1))\n",
    "    occupation_arr = pd.get_dummies(node_user['occupation']).to_numpy()\n",
    "\n",
    "    user_feature = np.concatenate([age, gender_arr, occupation_arr], axis=1)\n",
    "\n",
    "    return user_feature\n",
    "\n",
    "\n",
    "def get_movie_side_feature(node_movie: pd.DataFrame):\n",
    "    \"\"\"电影节点属性特征，主要是电影类型\"\"\"\n",
    "    movie_genre_cols = ['Action', 'Adventure', 'Animation',\n",
    "                        'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                        'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                        'Thriller', 'War', 'Western']\n",
    "    movie_genre_arr = node_movie.loc[:,\n",
    "                                     movie_genre_cols].to_numpy().astype('float32')\n",
    "    return movie_genre_arr\n",
    "\n",
    "\n",
    "def convert_to_homogeneous(user_feature: np.ndarray, movie_feature: np.ndarray):\n",
    "    \"\"\"通过补零将用户和电影的属性特征对齐到同一维度\"\"\"\n",
    "    num_user, user_feature_dim = user_feature.shape\n",
    "    num_movie, movie_feature_dim = movie_feature.shape\n",
    "    user_feature = np.concatenate(\n",
    "        [user_feature, np.zeros((num_user, movie_feature_dim))], axis=1)\n",
    "    movie_feature = np.concatenate(\n",
    "        [np.zeros((num_movie, user_feature_dim)), movie_feature], axis=1)\n",
    "\n",
    "    return user_feature, movie_feature\n",
    "\n",
    "\n",
    "def normalize_feature(feature):\n",
    "    row_sum = feature.sum(1)\n",
    "    row_sum[row_sum == 0] = np.inf\n",
    "    normalized_feat = feature / row_sum.reshape(-1, 1)\n",
    "    return normalized_feat\n",
    "\n",
    "\n",
    "class MovielensDataset(object):\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "\n",
    "    def __init__(self, data_root=\"data\"):\n",
    "        self.data_root = data_root\n",
    "        self.maybe_download()\n",
    "\n",
    "    @staticmethod\n",
    "    def build_graph(edge_df: pd.DataFrame, user_df: pd.DataFrame,\n",
    "                    movie_df: pd.DataFrame, symmetric_normalization=False):\n",
    "        node_user = edge_df[['user_node']\n",
    "                            ].drop_duplicates().sort_values('user_node')\n",
    "        node_movie = edge_df[['movie_node']\n",
    "                             ].drop_duplicates().sort_values('movie_node')\n",
    "        node_user.loc[:, 'user_node_id'] = range(len(node_user))\n",
    "        node_movie.loc[:, 'movie_node_id'] = range(len(node_movie))\n",
    "\n",
    "        edge_df = edge_df.merge(node_user, on='user_node', how='left')\\\n",
    "            .merge(node_movie, on='movie_node', how='left')\n",
    "\n",
    "        node_user = node_user.merge(user_df, on='user_node', how='left')\n",
    "        node_movie = node_movie.merge(movie_df, on='movie_node', how='left')\n",
    "        num_user = len(node_user)\n",
    "        num_movie = len(node_movie)\n",
    "\n",
    "        # adjacency\n",
    "        user2movie_adjacencies, movie2user_adjacencies = get_adjacency(edge_df, num_user, num_movie,\n",
    "                                                                       symmetric_normalization)\n",
    "\n",
    "        # node property feature\n",
    "        user_side_feature = get_user_side_feature(node_user)\n",
    "        movie_side_feature = get_movie_side_feature(node_movie)\n",
    "        user_side_feature = normalize_feature(user_side_feature)\n",
    "        movie_side_feature = normalize_feature(movie_side_feature)\n",
    "        user_side_feature, movie_side_feature = convert_to_homogeneous(user_side_feature,\n",
    "                                                                       movie_side_feature)\n",
    "\n",
    "        # one-hot encoding for nodes\n",
    "        user_identity_feature, movie_indentity_feature = get_node_identity_feature(\n",
    "            num_user, num_movie)\n",
    "\n",
    "        # user_indices, movie_indices, labels, train_mask\n",
    "        user_indices, movie_indices, labels = edge_df[[\n",
    "            'user_node_id', 'movie_node_id', 'ratings']].to_numpy().T\n",
    "        train_mask = (edge_df['usage'] == 'train').to_numpy()\n",
    "\n",
    "        return user2movie_adjacencies, movie2user_adjacencies, \\\n",
    "            user_side_feature, movie_side_feature, \\\n",
    "            user_identity_feature, movie_indentity_feature, \\\n",
    "            user_indices, movie_indices, labels, train_mask\n",
    "\n",
    "    def read_data(self):\n",
    "        data_dir = os.path.join(self.data_root, \"ml-100k\")\n",
    "        # edge data\n",
    "        edge_train = pd.read_csv(os.path.join(data_dir, 'u1.base'), sep='\\t',\n",
    "                                 header=None, names=['user_node', 'movie_node', 'ratings', 'timestamp'])\n",
    "        edge_train.loc[:, 'usage'] = 'train'\n",
    "        edge_test = pd.read_csv(os.path.join(data_dir, 'u1.test'), sep='\\t',\n",
    "                                header=None, names=['user_node', 'movie_node', 'ratings', 'timestamp'])\n",
    "        edge_test.loc[:, 'usage'] = 'test'\n",
    "        edge_df = pd.concat((edge_train, edge_test),\n",
    "                            axis=0).drop(columns='timestamp')\n",
    "        edge_df.loc[:, 'ratings'] -= 1\n",
    "        # item feature\n",
    "        sep = r'|'\n",
    "        movie_file = os.path.join(data_dir, 'u.item')\n",
    "        movie_headers = ['movie_node', 'movie_title', 'release_date', 'video_release_date',\n",
    "                         'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "                         'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                         'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                         'Thriller', 'War', 'Western']\n",
    "        movie_df = pd.read_csv(movie_file, sep=sep, header=None,\n",
    "                               names=movie_headers, encoding='latin1')\n",
    "        # user feature\n",
    "        users_file = os.path.join(data_dir, 'u.user')\n",
    "        users_headers = ['user_node', 'age',\n",
    "                         'gender', 'occupation', 'zip_code']\n",
    "        users_df = pd.read_csv(users_file, sep=sep, header=None,\n",
    "                               names=users_headers, encoding='latin1')\n",
    "        return edge_df, users_df, movie_df\n",
    "\n",
    "    def maybe_download(self):\n",
    "        save_path = os.path.join(self.data_root)\n",
    "        if not os.path.exists(save_path):\n",
    "            self.download_data(self.url, save_path)\n",
    "        if not os.path.exists(os.path.join(self.data_root, \"ml-100k\")):\n",
    "            zipfilename = os.path.join(self.data_root, \"ml-100k.zip\")\n",
    "            with ZipFile(zipfilename, \"r\") as zipobj:\n",
    "                zipobj.extractall(os.path.join(self.data_root))\n",
    "                print(\"Extracting data from {}\".format(zipfilename))\n",
    "\n",
    "    @staticmethod\n",
    "    def download_data(url, save_path):\n",
    "        \"\"\"数据下载工具，当原始数据不存在时将会进行下载\"\"\"\n",
    "        print(\"Downloading data from {}\".format(url))\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        request = urllib.request.urlopen(url)\n",
    "        filename = os.path.basename(url)\n",
    "        with open(os.path.join(save_path, filename), 'wb') as f:\n",
    "            f.write(request.read())\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetrically normalizing bipartite adj\n",
      "Asymmetrically normalizing bipartite adj\n"
     ]
    }
   ],
   "source": [
    "data = MovielensDataset()\n",
    "user2movie_adjacencies, movie2user_adjacencies, \\\n",
    "    user_side_feature, movie_side_feature, \\\n",
    "    user_identity_feature, movie_indentity_feature, \\\n",
    "    user_indices, movie_indices, labels, train_mask = data.build_graph(\n",
    "        *data.read_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InputDropout(nn.Module):\n",
    "    def __init__(self, keep_prob):\n",
    "        super(InputDropout, self).__init__()\n",
    "        self.p = keep_prob\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.clone()\n",
    "        if self.training:\n",
    "            random_tensor = self.p + torch.rand((inputs.size(0),))\n",
    "            dropout_mask = torch.floor(random_tensor).bool()\n",
    "            x[~dropout_mask] = 0.\n",
    "            return x / self.p\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class StackGCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_support,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False, activation=F.relu):\n",
    "        \"\"\"对得到的每类评分使用级联的方式进行聚合\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            num_support (int): 评分的类别数，比如1~5分，值为5\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "        \"\"\"\n",
    "        super(StackGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        assert output_dim % num_support == 0\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        \"\"\"StackGCNEncoder计算逻辑\n",
    "        \n",
    "        Args:\n",
    "            user_supports (list of torch.sparse.FloatTensor): \n",
    "                归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "            item_supports (list of torch.sparse.FloatTensor):\n",
    "                归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "            user_inputs (torch.Tensor): 用户特征的输入\n",
    "            item_inputs (torch.Tensor): 商品特征的输入\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 用户的隐层特征\n",
    "            [torch.Tensor]: 商品的隐层特征\n",
    "        \"\"\"\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weights = torch.split(self.weight, self.output_dim//self.num_support, dim=1)\n",
    "        for i in range(self.num_support):\n",
    "            tmp_u = torch.matmul(user_inputs, weights[i])\n",
    "            tmp_v = torch.matmul(item_inputs, weights[i])\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i], tmp_v)\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i], tmp_u)\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden = torch.cat(user_hidden, dim=1)\n",
    "        item_hidden = torch.cat(item_hidden, dim=1)\n",
    "\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_hidden)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class SumGCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_support,\n",
    "                 dropout=0.,\n",
    "                 use_bias=False, activation=F.relu):\n",
    "        \"\"\"对得到的每类评分使用求和的方式进行聚合\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            num_support (int): 评分的类别数，比如1~5分，值为5\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "        \"\"\"\n",
    "        super(SumGCNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_support = num_support\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.weight = nn.Parameter(torch.Tensor(\n",
    "            input_dim, output_dim * num_support))\n",
    "        if self.use_bias:\n",
    "            self.bias_user = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "            self.bias_item = nn.Parameter(torch.Tensor(output_dim, ))\n",
    "        self.dropout = InputDropout(1 - dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias_user)\n",
    "            init.zeros_(self.bias_item)\n",
    "\n",
    "    def forward(self, user_supports, item_supports, user_inputs, item_inputs):\n",
    "        \"\"\"SumGCNEncoder计算逻辑\n",
    "        \n",
    "        Args:\n",
    "            user_supports (list of torch.sparse.FloatTensor): \n",
    "                归一化后每个评分等级对应的用户与商品邻接矩阵\n",
    "            item_supports (list of torch.sparse.FloatTensor):\n",
    "                归一化后每个评分等级对应的商品与用户邻接矩阵\n",
    "            user_inputs (torch.Tensor): 用户特征的输入\n",
    "            item_inputs (torch.Tensor): 商品特征的输入\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 用户的隐层特征\n",
    "            [torch.Tensor]: 商品的隐层特征\n",
    "        \"\"\"\n",
    "        assert len(user_supports) == len(item_supports) == self.num_support\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "\n",
    "        user_hidden = []\n",
    "        item_hidden = []\n",
    "        weights = torch.split(self.weight, self.output_dim, dim=1)\n",
    "        for i in range(self.num_support):\n",
    "            w = sum(weights[:(i + 1)])\n",
    "            tmp_u = torch.matmul(user_inputs, w)\n",
    "            tmp_v = torch.matmul(item_inputs, w)\n",
    "            tmp_user_hidden = torch.sparse.mm(user_supports[i], tmp_v)\n",
    "            tmp_item_hidden = torch.sparse.mm(item_supports[i], tmp_u)\n",
    "            user_hidden.append(tmp_user_hidden)\n",
    "            item_hidden.append(tmp_item_hidden)\n",
    "\n",
    "        user_hidden, item_hidden = sum(user_hidden), sum(item_hidden)\n",
    "        user_outputs = self.activation(user_hidden)\n",
    "        item_outputs = self.activation(item_hidden)\n",
    "\n",
    "        if self.use_bias:\n",
    "            user_outputs += self.bias_user\n",
    "            item_outputs += self.bias_item\n",
    "\n",
    "        return user_outputs, item_outputs\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.,\n",
    "                 use_bias=False, activation=F.relu,\n",
    "                 share_weights=False):\n",
    "        \"\"\"非线性变换层\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            output_dim (int): 输出的特征维度，需要output_dim % num_support = 0\n",
    "            use_bias (bool, optional): 是否使用偏置. Defaults to False.\n",
    "            activation (optional): 激活函数. Defaults to F.relu.\n",
    "            share_weights (bool, optional): 用户和商品是否共享变换权值. Defaults to False.\n",
    "        \n",
    "        \"\"\"\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activation\n",
    "        self.share_weights = share_weights\n",
    "        if not share_weights:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.weights_u = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "            self.weights_v = self.weights_u\n",
    "            if use_bias:\n",
    "                self.user_bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "                self.item_bias = self.user_bias\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if not self.share_weights:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            init.xavier_uniform_(self.weights_v)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "                init.normal_(self.item_bias, std=0.5)\n",
    "        else:\n",
    "            init.xavier_uniform_(self.weights_u)\n",
    "            if self.use_bias:\n",
    "                init.normal_(self.user_bias, std=0.5)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs):\n",
    "        \"\"\"前向传播\n",
    "        \n",
    "        Args:\n",
    "            user_inputs (torch.Tensor): 输入的用户特征\n",
    "            item_inputs (torch.Tensor): 输入的商品特征\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 输出的用户特征\n",
    "            [torch.Tensor]: 输出的商品特征\n",
    "        \"\"\"\n",
    "        x_u = self.dropout(user_inputs)\n",
    "        x_u = torch.matmul(x_u, self.weights_u)\n",
    "\n",
    "        x_v = self.dropout(item_inputs)\n",
    "        x_v = torch.matmul(x_v, self.weights_v)\n",
    "\n",
    "        u_outputs = self.activation(x_u)\n",
    "        v_outputs = self.activation(x_v)\n",
    "\n",
    "        if self.use_bias:\n",
    "            u_outputs += self.user_bias\n",
    "            v_outputs += self.item_bias\n",
    "\n",
    "        return u_outputs, v_outputs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_weights, num_classes, dropout=0., activation=F.relu):\n",
    "        \"\"\"解码器\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): 输入的特征维度\n",
    "            num_weights (int): basis weight number\n",
    "            num_classes (int): 总共的评分级别数，eg. 5\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_weights = num_weights\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.weight = nn.ParameterList([nn.Parameter(torch.Tensor(input_dim, input_dim))\n",
    "                                        for _ in range(num_weights)])\n",
    "        self.weight_classifier = nn.Parameter(torch.Tensor(num_weights, num_classes))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            init.orthogonal_(self.weight[i], gain=1.1)\n",
    "        init.xavier_uniform_(self.weight_classifier)\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs, user_indices, item_indices):\n",
    "        \"\"\"计算非归一化的分类输出\n",
    "        \n",
    "        Args:\n",
    "            user_inputs (torch.Tensor): 用户的隐层特征\n",
    "            item_inputs (torch.Tensor): 商品的隐层特征\n",
    "            user_indices (torch.LongTensor): \n",
    "                所有交互行为中用户的id索引，与对应的item_indices构成一条边,shape=(num_edges, )\n",
    "            item_indices (torch.LongTensor): \n",
    "                所有交互行为中商品的id索引，与对应的user_indices构成一条边,shape=(num_edges, )\n",
    "        \n",
    "        Returns:\n",
    "            [torch.Tensor]: 未归一化的分类输出，shape=(num_edges, num_classes)\n",
    "        \"\"\"\n",
    "        user_inputs = self.dropout(user_inputs)\n",
    "        item_inputs = self.dropout(item_inputs)\n",
    "        user_inputs = user_inputs[user_indices]\n",
    "        item_inputs = item_inputs[item_indices]\n",
    "        \n",
    "        basis_outputs = []\n",
    "        for i in range(self.num_weights):\n",
    "            tmp = torch.matmul(user_inputs, self.weight[i])\n",
    "            out = torch.sum(tmp * item_inputs, dim=1, keepdim=True)\n",
    "            basis_outputs.append(out)\n",
    "\n",
    "        basis_outputs = torch.cat(basis_outputs, dim=1)\n",
    "        \n",
    "        outputs = torch.matmul(basis_outputs, self.weight_classifier)\n",
    "        outputs = self.activation(outputs)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######hyper\n",
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "LEARNING_RATE = 0.015\n",
    "EPOCHS = 1000\n",
    "NODE_INPUT_DIM = 2625\n",
    "SIDE_FEATURE_DIM = 41\n",
    "GCN_HIDDEN_DIM = 500\n",
    "SIDE_HIDDEN_DIM = 10\n",
    "ENCODE_HIDDEN_DIM = 75\n",
    "NUM_BASIS = 4\n",
    "DROPOUT_RATIO = 0.55\n",
    "WEIGHT_DACAY = 0.\n",
    "######hyper\n",
    "\n",
    "\n",
    "SCORES = torch.tensor([[1, 2, 3, 4, 5]]).to(DEVICE)\n",
    "\n",
    "\n",
    "def to_torch_sparse_tensor(x, device):\n",
    "    if not sp.isspmatrix_coo(x):\n",
    "        x = sp.coo_matrix(x)\n",
    "    row, col = x.row, x.col\n",
    "    data = x.data\n",
    "\n",
    "    indices = torch.from_numpy(np.asarray([row, col]).astype('int64')).long()\n",
    "    values = torch.from_numpy(x.data.astype(np.float32))\n",
    "    th_sparse_tensor = torch.sparse.FloatTensor(indices, values,\n",
    "                                                x.shape).to(device)\n",
    "\n",
    "    return th_sparse_tensor\n",
    "\n",
    "\n",
    "def tensor_from_numpy(x, device):\n",
    "\n",
    "    return torch.from_numpy(x).to(device)\n",
    "\n",
    "\n",
    "class GraphMatrixCompletion(nn.Module):\n",
    "    def __init__(self, input_dim, side_feat_dim,\n",
    "                 gcn_hidden_dim, side_hidden_dim,\n",
    "                 encode_hidden_dim,\n",
    "                 num_support=5, num_classes=5, num_basis=3):\n",
    "        super(GraphMatrixCompletion, self).__init__()\n",
    "        self.encoder = StackGCNEncoder(input_dim, gcn_hidden_dim, num_support, DROPOUT_RATIO)\n",
    "        self.dense1 = FullyConnected(side_feat_dim, side_hidden_dim, dropout=0.,\n",
    "                                     use_bias=True)\n",
    "        self.dense2 = FullyConnected(gcn_hidden_dim + side_hidden_dim, encode_hidden_dim,\n",
    "                                     dropout=DROPOUT_RATIO, activation=lambda x: x)\n",
    "        self.decoder = Decoder(encode_hidden_dim, num_basis, num_classes,\n",
    "                               dropout=DROPOUT_RATIO, activation=lambda x: x)\n",
    "\n",
    "    def forward(self, user_supports, item_supports,\n",
    "                user_inputs, item_inputs,\n",
    "                user_side_inputs, item_side_inputs,\n",
    "                user_edge_idx, item_edge_idx):\n",
    "        user_gcn, movie_gcn = self.encoder(user_supports, item_supports, user_inputs, item_inputs)\n",
    "        user_side_feat, movie_side_feat = self.dense1(user_side_inputs, item_side_inputs)\n",
    "\n",
    "        user_feat = torch.cat((user_gcn, user_side_feat), dim=1)\n",
    "        movie_feat = torch.cat((movie_gcn, movie_side_feat), dim=1)\n",
    "\n",
    "        user_embed, movie_embed = self.dense2(user_feat, movie_feat)\n",
    "\n",
    "        edge_logits = self.decoder(user_embed, movie_embed, user_edge_idx, item_edge_idx)\n",
    "\n",
    "        return edge_logits\n",
    "\n",
    "\n",
    "data = MovielensDataset()\n",
    "user2movie_adjacencies, movie2user_adjacencies, \\\n",
    "    user_side_feature, movie_side_feature, \\\n",
    "    user_identity_feature, movie_identity_feature, \\\n",
    "    user_indices, movie_indices, labels, train_mask = data.build_graph(\n",
    "        *data.read_data())\n",
    "\n",
    "user2movie_adjacencies = [to_torch_sparse_tensor(adj, DEVICE) for adj in user2movie_adjacencies]\n",
    "movie2user_adjacencies = [to_torch_sparse_tensor(adj, DEVICE) for adj in movie2user_adjacencies]\n",
    "user_side_feature = tensor_from_numpy(user_side_feature, DEVICE).float()\n",
    "movie_side_feature = tensor_from_numpy(movie_side_feature, DEVICE).float()\n",
    "user_identity_feature = tensor_from_numpy(user_identity_feature, DEVICE).float()\n",
    "movie_identity_feature = tensor_from_numpy(movie_identity_feature, DEVICE).float()\n",
    "user_indices = tensor_from_numpy(user_indices, DEVICE).long()\n",
    "movie_indices = tensor_from_numpy(movie_indices, DEVICE).long()\n",
    "labels = tensor_from_numpy(labels, DEVICE)\n",
    "train_mask = tensor_from_numpy(train_mask, DEVICE)\n",
    "\n",
    "\n",
    "model = GraphMatrixCompletion(NODE_INPUT_DIM, SIDE_FEATURE_DIM, GCN_HIDDEN_DIM,\n",
    "                              SIDE_HIDDEN_DIM, ENCODE_HIDDEN_DIM, num_basis=NUM_BASIS).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DACAY)\n",
    "model_inputs = (user2movie_adjacencies, movie2user_adjacencies,\n",
    "                user_identity_feature, movie_identity_feature,\n",
    "                user_side_feature, movie_side_feature, user_indices, movie_indices)\n",
    "\n",
    "def train():\n",
    "    test_result = []\n",
    "    model.train()\n",
    "    for e in range(EPOCHS):\n",
    "        logits = model(*model_inputs)\n",
    "        loss = criterion(logits[train_mask], labels[train_mask])\n",
    "        rmse = expected_rmse(logits[train_mask], labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # 反向传播计算参数的梯度\n",
    "        optimizer.step()  # 使用优化方法进行梯度更新\n",
    "\n",
    "        tr = test()\n",
    "        test_result.append(tr)\n",
    "        model.train()\n",
    "        print(f\"Epoch {e:04d}: TrainLoss: {loss.item():.4f}, TrainRMSE: {rmse.item():.4f}, \"\n",
    "              f\"TestRMSE: {tr[0]:.4f}, TestLoss: {tr[1]:.4f}\")\n",
    "\n",
    "    test_result = np.asarray(test_result)\n",
    "    idx = test_result[:, 0].argmin()\n",
    "    print(f'test min rmse {test_result[idx]} on epoch {idx}')\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(*model_inputs)\n",
    "    test_mask = ~train_mask\n",
    "    loss = criterion(logits[test_mask], labels[test_mask])\n",
    "    rmse = expected_rmse(logits[test_mask], labels[test_mask])\n",
    "    return rmse.item(), loss.item()\n",
    "\n",
    "\n",
    "def expected_rmse(logits, label):\n",
    "    true_y = label + 1  # 原来的评分为1~5，作为label时为0~4\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    pred_y = torch.sum(prob * SCORES, dim=1)\n",
    "    \n",
    "    diff = torch.pow(true_y - pred_y, 2)\n",
    "    \n",
    "    return torch.sqrt(diff.mean())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca001f4215888d8ea16b51ee26d57194a73bf1104676f49e8f5e52e35be82f9f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch1.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
